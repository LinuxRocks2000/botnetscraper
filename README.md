# botnetscraper
Collab project for a webscraping CPU-sharing adaptive decentralized botnet

The idea is to be able to webscrape *simulatenously* with decentralized adaptive servers (in other words, servers can join and leave without destroying the net) managing clients, which do the actual computation (running a server as a client as well is possible). In this way we can webscrape large swaths of the Internet without waiting years for our individual computers to do it, all of our computers do it together.
